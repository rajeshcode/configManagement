<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/hadoop/nn1/1,/mnt/nn1/1</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/hadoop/1/data,/hadoop/2/data,/hadoop/3/data,/hadoop/4/data,/hadoop/5/data,/hadoop/6/data,/hadoop/7/data,/hadoop/8/data,/hadoop/9/data,/hadoop/10/data,/hadoop/11/data,/hadoop/12/data</value> 
  </property>
  <property>
    <name>dfs.namenode.checkpoint.dir</name>
    <value>/hadoop/nn2/1</value>
    <final>true</final>
  </property>

 <property>
   <name>dfs.hosts</name>
   <!-- The files containing hosts allowed to connect to namenode -->
   <value>/apache/hadoop/etc/hadoop/hosts</value>
 </property>

 <property>
   <name>dfs.hosts.exclude</name>
   <!-- The files containing hosts allowed to connect to namenode -->
   <value>/apache/hadoop/etc/hadoop/hdfs-exclude</value>
 </property>

  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>3</value>
  </property>

  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>10485760</value>
  </property>

<property>
   <!-- Amount of space which HDFS will refuse to use in bytes -->
   <name>dfs.datanode.du.reserved</name>
   <value>107374182400</value> <!-- 100 GB-->
</property>

<property>
  <name>dfs.heartbeat.interval</name>
  <value>6</value>
  <description>how frequently dn send a heartbeat.</description>
</property>

<property>
  <name>dfs.blockreport.intervalMsec</name>
  <value>21600000</value>
  <description>how frequently dn send a blockreport.</description>
</property>

<property>
   <name>dfs.safemode.threshold.pct</name>
   <value>1.0f</value>
   <!-- Allows 10 blocks unreported out of 10,000,000 -->
   <description>
        Specifies the percentage of blocks that should satisfy
        the minimal replication requirement defined by dfs.replication.min.
        Values less than or equal to 0 mean not to start in safe mode.
        Values greater than 1 will make safe mode permanent.
   </description>
</property>

<property>
   <name>dfs.safemode.extension</name>
   <value>120000</value>
   <!-- 2 minutes -->
   <description> Determines extension of safe mode in milliseconds after the threshold level is reached. </description>
</property>

<property>
<name>dfs.permissions</name>
<value>true</value>
<description>
If "true", enable permission checking in HDFS.
If "false", permission checking is turned off,
but all other behavior is unchanged.
Switching from one parameter value to the other does not change the mode,
owner or group of files or directories.
</description>
</property>

  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>134217728</value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>128</value>
  </property>
  <property>
    <name>dfs.datanode.handler.count</name>
    <value>50</value>
  </property>
  <property>
    <name>dfs.datanode.max.xcievers</name>
    <value>4096</value>
  </property>
<property>
  <name>dfs.max-repl-streams</name>
  <value>40</value>
</property>

<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>

<property>
  <name>dfs.http.address</name>
  <value>apollo-phx-nn.vip.ebay.com:50070</value>
  <description>
    The address and the base port where the dfs namenode web ui will listen on.
    If the port is 0 then the server will start on a free port.
  </description>
</property>

<property>
  <name>dfs.secondary.http.address</name>
  <value>apollo-phx-sn.vip.ebay.com:50090</value>
  <description>
    The secondary namenode http server address and port.
    If the port is 0 then the server will start on a free port.
  </description>
</property>
<property>
    <name>dfs.block.local-path-access.user</name>
    <value>hadoop</value>
    <description>the user who is allowed to perform short
    circuit reads.
    </description>
</property>
<property>
<name>dfs.block.access.token.enable</name>
<value>true</value>
</property>

<!-- NameNode security config -->
<property>
  <name>dfs.web.authentication.kerberos.keytab</name>
  <value>/etc/hadoop/hadoop.keytab</value>
</property>
<property>
  <name>dfs.namenode.kerberos.internal.spnego.principal</name>
  <value>HTTP/_HOST@APD.EBAY.COM</value>
</property>
<property>
  <name>dfs.namenode.keytab.file</name>
  <value>/etc/hadoop/hadoop.keytab</value>
</property>
<property>
  <name>dfs.namenode.kerberos.principal</name>
  <value>hadoop/_HOST@APD.EBAY.COM</value>
<!-- _HOST will be replaced by the the domain name present in fs.default.name. It is better to use the actual host name  -->
</property>
<property>
  <name>dfs.web.authentication.kerberos.principal</name>
  <value>HTTP/_HOST@APD.EBAY.COM</value>
</property>

<!-- Secondary NameNode security config -->
<property>
  <name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name>
  <value>HTTP/_HOST@APD.EBAY.COM</value>
</property>
<property>
  <name>dfs.secondary.namenode.keytab.file</name>
  <value>/etc/hadoop/hadoop.keytab</value>
</property>
<property>
  <name>dfs.secondary.namenode.kerberos.principal</name>
  <value>hadoop/_HOST@APD.EBAY.COM</value>
</property>
<!-- DataNode security config -->
<property>
  <name>dfs.datanode.data.dir.perm</name>
  <value>700</value>
  </property>
<property>
  <name>dfs.datanode.address</name>
  <value>0.0.0.0:1004</value>
</property>
<property>
  <name>dfs.datanode.http.address</name>
  <value>0.0.0.0:1006</value>
</property>
<property>
  <name>dfs.datanode.keytab.file</name>
  <value>/etc/hadoop/hadoop.keytab</value>
</property>
<property>
  <name>dfs.datanode.kerberos.principal</name>
  <value>hadoop/_HOST@APD.EBAY.COM</value>
  <!-- _HOST will be replaced by the frst domain name mapped to the ip -->
</property>
<property>
  <name>dfs.cluster.administrators</name>
  <value> hdmi-hadoopeng</value>
</property>

<property>
  <name>dfs.namenode.name.dir.restore</name>
  <value>true</value>
</property>

<property>
  <name>dfs.ls.limit</name>
  <value>4096</value>
</property>

</configuration>
